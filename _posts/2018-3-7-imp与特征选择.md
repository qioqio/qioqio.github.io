---
layout: post
title: imp与特征选择
subtitle:  
date: 2018-3-7 
author: qioqio
header-img: img/Pingguo37.jpg
catalog: true
tags:                             
- 特征选择
- imp
---

之前,在上模式识别课程的时候就发现特征选择和imp问题有很多相似的地方.
关于特征选择不明白的话,可以在网上随便搜索一下.
如果关于imp问题不明白的话,可以看看这篇我写的[博客](www.cnblogs.com/qioqio/p/7978837.html)

特征选择问题是在很多的特征之中选择一些少量的一些特征来进行学习.
influence maximization 则是在很多的种子节点之中选择影响力尽可能大的那些节点.
今天看了西瓜书上,关于特征选择那一部分,解释了好多我没有听过的概念
我想在这里把这两个领域的不同问题的相似地方点出来,如有错误,欢迎批评指正

特征选择有过滤式选择 包裹式选择和嵌入式选择.
这三种选择方式各自有自己的鲜明特点,首先过滤式选择是不针对我们的问题进行优化的,也就是说得到的特征可能对于我们的分类问题没有什么帮助,但是只要这个特征带来的信息熵足够的大,那么就会被选入,感觉这个和imp问题之中的启发式算法很像,比如,degree-count算法就是抓住节点的度这个特征来对不同的节点的影响力作出一个评估,然后直接进行选择,选出来的结果的有效性虽然没有理论上的证明,但是大概率是好使的.这个和机器学习算法很像??(瞎说的)

第二个包裹式选择就是针对我们的目标函数进行优化,我们在特征集合之中挑选出一些特征进行分类,看看效果如何,不好的话,我们换另外的一组特征,好的话,接着用,但是这带来的问题就是计算量过于庞大.所以我们往往要设计出好的算法来加速这个过程.感觉这个和imp问题之中的主流算法贪心算法就比较相似,我们的贪心算法就是一次选中一个种子节点,直到我们找到我们想要的为止.

第三个是我觉得最难以理解的特征选择方法了(我到现在也没有理解上去,如果你知道的话,可以给我私信邮件,如果你可以科学上网的话,也可以直接在下方评论)我看了一些解释还是没看懂,大概意思好像是把特征选择和训练过程结合在一起,训练的过程直接把没有用的特征给删除掉.
但是针对这个方法,我们的imp问题好像并没有办法与之对应,或许只是我不知道而已.

既然这两个问题这么相似,我们是不是可以把前人的工作总结一下,方法互相借鉴一下,如果可能的话.
为什么没有论文来说这个事情呢??是发这样的论文太low吗?懵逼脸








